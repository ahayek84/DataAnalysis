{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASS FOR DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer\n",
    "\n",
    "class PandasSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x.loc[:,self.columns]\n",
    "\n",
    "class ExtractNameAttributes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes=[\"lname\",\"title\",\"spname\"]):\n",
    "        self.attributes = attributes\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = x.iloc[:,0]\n",
    "        data = pd.DataFrame()\n",
    "        try:\n",
    "            data[self.attributes[0]] = x.map(lambda x:x.split(',')[0].strip())\n",
    "            data[self.attributes[1]] = x.str.extract(\"\\,(.*?)\\.\", expand=False)\n",
    "            try:\n",
    "                data[self.attributes[2]] = x.map(lambda x:x.split('.')[1].split('(')[0].strip())\n",
    "            except IndexError:\n",
    "                data[self.attributes[2]] = x.map(lambda x:x.split('.')[1].strip())\n",
    "            ## data[self.attributes[3]] = x.str.extract(\"\\((.*?)\\)\", expand=False) 1088 out of 1309 are invalid\n",
    "        except:\n",
    "            pass\n",
    "        return data\n",
    "    \n",
    "class LabelEncoderPipelineFriendly(LabelEncoder):   \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"this would allow us to fit the model based on the X input.\"\"\"\n",
    "        super(LabelEncoderPipelineFriendly, self).fit(X)\n",
    "    def transform(self, X, y=None):\n",
    "        return super(LabelEncoderPipelineFriendly, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        for colname in X:\n",
    "            X[colname] = super(LabelEncoderPipelineFriendly, self).fit(X[colname]).transform(X[colname])\n",
    "        return X\n",
    "\n",
    "\n",
    "class NullFiller(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,colname):\n",
    "        self.colname = colname\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        sc = self.colname[0]\n",
    "        dfs = x.groupby([sc])[sc].agg({\"percentage\": np.size})/len(x)\n",
    "        dfs = dfs.reset_index()\n",
    "        xval = np.max(dfs[\"percentage\"])\n",
    "        xlab = dfs[dfs[\"percentage\"] == xval]\n",
    "        x = x.fillna(xlab[sc].values[0])\n",
    "        return x\n",
    "    \n",
    "class PandasToArr(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        for colname in x:\n",
    "            x[colname] = x[colname].values.reshape(-1, 1) \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TITANIC CODE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "com_df = test_df.append(train_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309 418 891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3101298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare                                          Name  \\\n",
       "0  34.5   NaN        Q   7.8292                              Kelly, Mr. James   \n",
       "1  47.0   NaN        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2  62.0   NaN        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "3  27.0   NaN        S   8.6625                              Wirz, Mr. Albert   \n",
       "4  22.0   NaN        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp  Survived   Ticket  \n",
       "0      0          892       3    male      0       NaN   330911  \n",
       "1      0          893       3  female      1       NaN   363272  \n",
       "2      0          894       2    male      0       NaN   240276  \n",
       "3      0          895       3    male      0       NaN   315154  \n",
       "4      1          896       3  female      1       NaN  3101298  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(com_df),len(test_df),len(train_df))\n",
    "com_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 132.9+ KB\n"
     ]
    }
   ],
   "source": [
    "com_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TITANIC PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1309, 11)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Use lable Encoders and Binarizers before the PipleLine \n",
    "#lb_enc = LabelEncoder()\n",
    "#com_df['Embarked_enc'] = lb_enc.fit_transform(com_df['Embarked'])\n",
    "#com_df['Sex_enc'] = lb_enc.fit_transform(com_df['Sex'])\n",
    "\n",
    "##PipeLine \n",
    "processing_pipeline = make_pipeline(\n",
    "    # Select used variables\n",
    "    PandasSelector([\"Age\", \"Embarked\", \n",
    "                    \"Fare\", \"Name\", \"Parch\",\n",
    "                    \"PassengerId\", \"Pclass\",\n",
    "                    \"Sex\", \"SibSp\", \"Ticket\"]),\n",
    "    \n",
    "    # combine features\n",
    "    make_union(\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Age\"]),\n",
    "            Imputer(strategy='mean'),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Fare\"]),\n",
    "            Imputer(strategy='mean'),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Embarked\",\"Sex\"]),\n",
    "            NullFiller([\"Embarked\",\"Sex\"]),\n",
    "            LabelEncoderPipelineFriendly(),\n",
    "            PandasToArr(),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Name\"]),\n",
    "            ExtractNameAttributes(),\n",
    "            LabelEncoderPipelineFriendly(),\n",
    "            PandasToArr(),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Ticket\"]),\n",
    "            LabelEncoderPipelineFriendly(),\n",
    "            PandasToArr(),\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            PandasSelector([\"Pclass\",\"Parch\",\"SibSp\"]),\n",
    "            PandasToArr(),\n",
    "            StandardScaler()\n",
    "        )\n",
    "    )    \n",
    ")\n",
    "\n",
    "x = processing_pipeline.fit_transform(com_df)\n",
    "x = x.astype('float64')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## it is time to use algoritms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "####\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('et',ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "x =  processing_pipeline.fit_transform(train_df).astype('float64')\n",
    "xt = processing_pipeline.fit_transform(test_df).astype('float64')\n",
    "y = train_df['Survived']\n",
    "\n",
    "out = pd.DataFrame()\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    clf.fit(x,y)\n",
    "    out[clf_name] = clf.predict(xt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM gave the best score on Kaggle 0.79425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Survived'] = ''\n",
    "for cln in out.columns:\n",
    "    for row in test_df.itertuples():\n",
    "        test_df.loc[row.Index, 'Survived'] = out[cln].values[row.Index]\n",
    "    test_df.to_csv('titanic_pip'+cln+'.csv',columns=['PassengerId','Survived'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
